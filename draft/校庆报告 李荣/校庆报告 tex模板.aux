\relax 
\citation{zaremba2014learning}
\citation{zaremba2014learning}
\citation{gold1967language}
\citation{angluin1983inductive}
\citation{nordin1997evolutionary}
\citation{liang2013learning}
\citation{wineberg1994representation}
\citation{solomonoff1964formal}
\@writefile{toc}{\contentsline {section}{\numberline {1}引\hskip 1em\relax 言}{1}}
\citation{graves2014neural}
\citation{zaremba2015reinforcement}
\citation{kaiser2015neural}
\citation{kurach2015neural}
\citation{andrychowicz2016learning}
\citation{graves2014neural}
\citation{hochreiter1997long}
\citation{graves2014neural}
\citation{bengio2009curriculum}
\citation{gold1967language}
\citation{angluin1983inductive}
\citation{gulwani2010dimensions}
\citation{kitzelmann2009inductive}
\citation{graves2014neural}
\citation{kaiser2015neural}
\citation{kalchbrenner2015grid}
\citation{zaremba2015reinforcement}
\citation{graves2016hybrid}
\citation{weston2014memory}
\citation{vinyals2015pointer}
\citation{joulin2015inferring}
\citation{andrychowicz2016learning}
\@writefile{toc}{\contentsline {section}{\numberline {2}相关工作}{2}}
\citation{bengio2009curriculum}
\citation{zaremba2016learning}
\citation{sutskever2014sequence}
\@writefile{toc}{\contentsline {section}{\numberline {3}任务}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 三个任务的例子，从左到右分别是复制、加法和乘法。}}{3}}
\newlabel{Fig:task}{{1}{3}}
\citation{hochreiter1997long}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 每一个时间步$t$，控制器从外部获得输入$input[t]$，并计算得到一个输出$output[t]$。与此同时，控制器通过若干个的读头从记忆模块读取一个向量，并通过写头更新记忆模块。}}{4}}
\newlabel{Fig:ntm_architecture}{{2}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}模型}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}读机制}{4}}
\newlabel{equ:1}{{1}{4}}
\citation{graves2014neural}
\citation{bengio2009curriculum}
\citation{zaremba2014learning}
\newlabel{eqe:2}{{2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}写机制}{5}}
\newlabel{equ:3}{{3}{5}}
\newlabel{equ:4}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}寻址机制}{5}}
\newlabel{equ:content}{{5}{5}}
\newlabel{equ:interp}{{6}{5}}
\newlabel{equ:shift}{{7}{5}}
\newlabel{equ:sharp}{{8}{5}}
\newlabel{equ:cosine}{{9}{5}}
\newlabel{equ:k}{{10}{5}}
\newlabel{equ:b}{{11}{5}}
\newlabel{equ:g}{{12}{5}}
\newlabel{equ:s}{{13}{5}}
\newlabel{equ:b}{{14}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}实验}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}课程学习}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces 网络超参数}}{6}}
\newlabel{tab:superparameter}{{1}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}网络参数}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces 任务相关参数}}{6}}
\newlabel{tab:taskparameter}{{2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}实验结果}{6}}
\bibstyle{unsrt}
\bibdata{reference}
\bibcite{zaremba2014learning}{1}
\bibcite{gold1967language}{2}
\bibcite{angluin1983inductive}{3}
\bibcite{nordin1997evolutionary}{4}
\bibcite{liang2013learning}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 三种课程学习在测试集上的准确率的对比。纵轴表示的是模型在测试集上的准确率，横轴表示的是训练次数。绿色的“+”连成的曲线表示不用课程学习，蓝色的虚线表示的是使用混合的课程学习策略，红色的实线表示的是使用基于课程比例的课程学习课程。从图中可以看出基于课程比例的课程学习策略训练出来的模型性能最好，而不用课程学习策略训练的模型性能最差。}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{7}}
\newlabel{fig:result}{{3}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}总结与未来工作}{7}}
\bibcite{wineberg1994representation}{6}
\bibcite{solomonoff1964formal}{7}
\bibcite{graves2014neural}{8}
\bibcite{zaremba2015reinforcement}{9}
\bibcite{kaiser2015neural}{10}
\bibcite{kurach2015neural}{11}
\bibcite{andrychowicz2016learning}{12}
\bibcite{hochreiter1997long}{13}
\bibcite{bengio2009curriculum}{14}
\bibcite{gulwani2010dimensions}{15}
\bibcite{kitzelmann2009inductive}{16}
\bibcite{kalchbrenner2015grid}{17}
\bibcite{graves2016hybrid}{18}
\bibcite{weston2014memory}{19}
\bibcite{vinyals2015pointer}{20}
\bibcite{joulin2015inferring}{21}
\bibcite{zaremba2016learning}{22}
\bibcite{sutskever2014sequence}{23}
